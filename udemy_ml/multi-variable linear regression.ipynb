{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assumptions of linear regression\n",
    "- linearity - assuming each independent variable has a linear relationship with the dependent variable\n",
    "- homoscedasticity - same variance among independent variables\n",
    "    - failure would be if flower values are closer to regression line while higher values are further away\n",
    "- multivariate normality - assume residuals are normally distributed\n",
    "- independence of errors - errors do not depend on one another\n",
    "- lack of multicollinearity - one independent variable can be modelled to linearly predict another independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('50_Startups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what is a p-value\n",
    "- determines how off from the null hypothesis a given sample is\n",
    "- larger p-value -> more confident that null hypothesis is correct\n",
    "- smaller p-value -> less confident that null hypothesis is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 methods of building models\n",
    "- all in \n",
    "    - put all variables into model \n",
    "    - based on prior/domain knowledge\n",
    "    - preparing for backward elimination\n",
    "- backward elimination\n",
    "    1. select sig level to stay in model i.e SL = .05\n",
    "    2. fit full model with all indep. vars\n",
    "    3. consider the predictor with highest p-value if p-value > SL otherwise go to end\n",
    "    4. remove the predictor \n",
    "    5. fit model without this variable, then go back to step 3\n",
    "    6. finish until p-value are less than SL\n",
    "- forward selection\n",
    "    1. select sig level to stay in model i.e SL = .05\n",
    "    2. fit all simple reg model y ~ $x_n$ select one with lowest p-value\n",
    "    3. keep this variable and fit all posssible models with one extra predictor added to the ones you already have\n",
    "    4. consider the predictor with the lowest p-value, if p-value < SL then go to step 3, otherwise continue\n",
    "    5. keep previous model\n",
    "    \n",
    "- bidirectional elimination \n",
    "    1. select a sig level to enter and stay in the model\n",
    "        - SLENTER = .05 SLSTAY = .05\n",
    "    2. perform the next step of forward selection (new variable must have P < SLENTER to enter)\n",
    "    3. perform ALL steps of backward elimination (old variables must have P < SLSTAY) repeat step 2\n",
    "    4. no new variables can enter or stay -> finished model\n",
    "- score comparison\n",
    "    1. select criterion for success\n",
    "    2. construct all possible reg model $2^n - 1$ total combos\n",
    "    3. select one which meets criterion the best\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "X = pd.DataFrame(X)\n",
    "X.iloc[:, 3] = label_encoder.fit_transform(X.iloc[:, 3])\n",
    "one_hot = OneHotEncoder(categorical_features = [3])\n",
    "X = one_hot.fit_transform(X).toarray()\n",
    "\n",
    "# avoiding the dummy variable trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1          2          3          4\n",
       "0  0.0  1.0  165349.20  136897.80  471784.10\n",
       "1  0.0  0.0  162597.70  151377.59  443898.53\n",
       "2  1.0  0.0  153441.51  101145.55  407934.54\n",
       "3  0.0  1.0  144372.41  118671.85  383199.62\n",
       "4  1.0  0.0  142107.34   91391.77  366168.42"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_reg = LinearRegression()\n",
    "trained_reg = linear_reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column of ones to beginning of x so that statsmodel lib \n",
    "# understands that there is a constant\n",
    "X = np.append(arr= np.ones((50,1)).astype(int), values = X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing backward elimination by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:, [0,1,2,3,4,5]]\n",
    "ols_regressor = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#ols_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:, [0,1,3,4,5]]\n",
    "ols_regressor = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#ols_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:, [0,3,4,5]]\n",
    "ols_regressor = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#ols_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:, [0,3,5]]\n",
    "ols_regressor = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#ols_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_opt = X[:, [0,3]]\n",
    "ols_regressor = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "#ols_regressor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwards_elimination(X,indices,sl):\n",
    "    X_opt = X[:, indices]\n",
    "    tmp_reg = sm.OLS(endog=y,exog=X_opt).fit()\n",
    "    pvals = tmp_reg.pvalues\n",
    "    max_p = np.amax(pvals)\n",
    "    while(max_p > sl):\n",
    "        idx = np.where(pvals == max_p)[0][0]\n",
    "        del indices[idx]\n",
    "        X_opt = X[:, indices]\n",
    "        tmp_reg = sm.OLS(endog=y,exog=X_opt).fit()\n",
    "        pvals = tmp_reg.pvalues\n",
    "        max_p = np.amax(pvals)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 4, 5]\n",
      "[0, 3, 4, 5]\n",
      "[0, 3, 5]\n",
      "[0, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 3]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backwards_elimination(X, [0, 1, 2, 3, 4, 5], .05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
